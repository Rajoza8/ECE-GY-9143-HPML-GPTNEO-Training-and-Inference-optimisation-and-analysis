usage: pretrain_gpt.py [-h] [--num-layers NUM_LAYERS]
                       [--encoder-num-layers ENCODER_NUM_LAYERS]
                       [--decoder-num-layers DECODER_NUM_LAYERS]
                       [--num-experts NUM_EXPERTS [NUM_EXPERTS ...]]
                       [--mlp-type MLP_TYPE] [--topk TOPK]
                       [--expert-interval EXPERT_INTERVAL]
                       [--hidden-size HIDDEN_SIZE]
                       [--ffn-hidden-size FFN_HIDDEN_SIZE]
                       [--num-attention-heads NUM_ATTENTION_HEADS]
                       [--num-key-value-heads NUM_KEY_VALUE_HEADS]
                       [--kv-channels KV_CHANNELS]
                       [--max-position-embeddings MAX_POSITION_EMBEDDINGS]
                       [--use-rotary-position-embeddings]
                       [--rotary-percent ROTARY_PERCENT]
                       [--no-position-embedding]
                       [--make-vocab-size-divisible-by MAKE_VOCAB_SIZE_DIVISIBLE_BY]
                       [--normalization {layernorm,rmsnorm}]
                       [--layernorm-epsilon LAYERNORM_EPSILON]
                       [--apply-layernorm-1p] [--disable-mem-efficient-ln]
                       [--apply-residual-connection-post-layernorm]
                       [--openai-gelu] [--squared-relu] [--swiglu]
                       [--onnx-safe ONNX_SAFE] [--bert-no-binary-head]
                       [--num-experts-switch NUM_EXPERTS_SWITCH]
                       [--untie-embeddings-and-output-weights]
                       [--embedding-weights-in-fp32]
                       [--attention-dropout ATTENTION_DROPOUT]
                       [--hidden-dropout HIDDEN_DROPOUT]
                       [--weight-decay WEIGHT_DECAY]
                       [--start-weight-decay START_WEIGHT_DECAY]
                       [--end-weight-decay END_WEIGHT_DECAY]
                       [--weight-decay-incr-style {constant,linear,cosine}]
                       [--clip-grad CLIP_GRAD] [--adam-beta1 ADAM_BETA1]
                       [--adam-beta2 ADAM_BETA2] [--adam-eps ADAM_EPS]
                       [--sgd-momentum SGD_MOMENTUM]
                       [--micro-batch-size MICRO_BATCH_SIZE]
                       [--batch-size BATCH_SIZE]
                       [--global-batch-size GLOBAL_BATCH_SIZE]
                       [--rampup-batch-size [RAMPUP_BATCH_SIZE ...]]
                       [--recompute-activations]
                       [--recompute-granularity {full,selective}]
                       [--distribute-saved-activations]
                       [--recompute-method {uniform,block}]
                       [--recompute-num-layers RECOMPUTE_NUM_LAYERS]
                       [--checkpoint-activations]
                       [--distribute-checkpointed-activations]
                       [--checkpoint-num-layers CHECKPOINT_NUM_LAYERS]
                       [--train-iters TRAIN_ITERS]
                       [--train-samples TRAIN_SAMPLES]
                       [--train-tokens TRAIN_TOKENS] [--random-ltd]
                       [--log-interval LOG_INTERVAL]
                       [--exit-interval EXIT_INTERVAL]
                       [--exit-duration-in-mins EXIT_DURATION_IN_MINS]
                       [--exit-signal-handler]
                       [--tensorboard-dir TENSORBOARD_DIR]
                       [--no-masked-softmax-fusion] [--no-bias-gelu-fusion]
                       [--no-bias-dropout-fusion]
                       [--disable-moe-token-dropping]
                       [--moe-train-capacity-factor MOE_TRAIN_CAPACITY_FACTOR]
                       [--moe-eval-capacity-factor MOE_EVAL_CAPACITY_FACTOR]
                       [--moe-min-capacity MOE_MIN_CAPACITY]
                       [--moe-loss-coeff MOE_LOSS_COEFF]
                       [--create-moe-param-group] [--use-flash-attn]
                       [--use-flash-attn-v2] [--use-flash-attn-triton]
                       [--disable-bias-linear] [--optimizer {adam,sgd}]
                       [--dataloader-type {single,cyclic}] [--ds-inference]
                       [--cpu-optimizer] [--cpu_torch_adam]
                       [--no-pipeline-parallel] [--use-tutel] [--inference]
                       [--no-async-tensor-model-parallel-allreduce]
                       [--no-persist-layer-norm] [--sequence-parallel]
                       [--ds-sequence-parallel-size DS_SEQUENCE_PARALLEL_SIZE]
                       [--force-ds-sequence-parallel]
                       [--no-gradient-accumulation-fusion]
                       [--use-dataset-only USE_DATASET_ONLY] [--seed SEED]
                       [--data-parallel-random-init]
                       [--init-method-std INIT_METHOD_STD]
                       [--init-method-xavier-uniform] [--lr LR]
                       [--lr-decay-style {constant,linear,cosine,inverse-square-root}]
                       [--lr-decay-iters LR_DECAY_ITERS]
                       [--lr-decay-samples LR_DECAY_SAMPLES]
                       [--lr-decay-tokens LR_DECAY_TOKENS]
                       [--lr-warmup-fraction LR_WARMUP_FRACTION]
                       [--lr-warmup-iters LR_WARMUP_ITERS]
                       [--lr-warmup-samples LR_WARMUP_SAMPLES]
                       [--lr-warmup-tokens LR_WARMUP_TOKENS] [--warmup WARMUP]
                       [--min-lr MIN_LR] [--override-opt_param-scheduler]
                       [--use-checkpoint-opt_param-scheduler] [--save SAVE]
                       [--save-interval SAVE_INTERVAL] [--no-save-optim]
                       [--no-save-rng] [--load LOAD] [--no-load-optim]
                       [--no-load-rng] [--no-load-lr-state] [--finetune]
                       [--no-initialization] [--use-checkpoint-args]
                       [--exit-on-missing-checkpoint] [--universal-checkpoint]
                       [--fp16] [--bf16] [--loss-scale LOSS_SCALE]
                       [--initial-loss-scale INITIAL_LOSS_SCALE]
                       [--min-loss-scale MIN_LOSS_SCALE]
                       [--loss-scale-window LOSS_SCALE_WINDOW]
                       [--hysteresis HYSTERESIS] [--fp32-residual-connection]
                       [--no-query-key-layer-scaling]
                       [--attention-softmax-in-fp32]
                       [--accumulate-allreduce-grads-in-fp32]
                       [--fp16-lm-cross-entropy]
                       [--tensor-model-parallel-size TENSOR_MODEL_PARALLEL_SIZE]
                       [--enable-expert-tensor-parallelism]
                       [--pipeline-model-parallel-size PIPELINE_MODEL_PARALLEL_SIZE]
                       [--pipeline-model-parallel-split-rank PIPELINE_MODEL_PARALLEL_SPLIT_RANK]
                       [--moe-expert-parallel-size MOE_EXPERT_PARALLEL_SIZE]
                       [--model-parallel-size MODEL_PARALLEL_SIZE]
                       [--num-layers-per-virtual-pipeline-stage NUM_LAYERS_PER_VIRTUAL_PIPELINE_STAGE]
                       [--overlap-p2p-communication]
                       [--distributed-backend {nccl,gloo,ccl}]
                       [--distributed-timeout-minutes DISTRIBUTED_TIMEOUT_MINUTES]
                       [--DDP-impl {local,torch,FSDP}]
                       [--no-contiguous-buffers-in-local-ddp]
                       [--no-scatter-gather-tensors-in-pipeline]
                       [--use-ring-exchange-p2p] [--local-rank LOCAL_RANK]
                       [--lazy-mpu-init LAZY_MPU_INIT]
                       [--use-cpu-initialization]
                       [--empty-unused-memory-level {0,1,2}]
                       [--standalone-embedding-stage]
                       [--use-distributed-optimizer] [--eval-iters EVAL_ITERS]
                       [--eval-interval EVAL_INTERVAL] [--skip-train]
                       [--aml-data-download-path AML_DATA_DOWNLOAD_PATH]
                       [--data-path [DATA_PATH ...]] [--split SPLIT]
                       [--train-data-path [TRAIN_DATA_PATH ...]]
                       [--valid-data-path [VALID_DATA_PATH ...]]
                       [--test-data-path [TEST_DATA_PATH ...]]
                       [--data-cache-path DATA_CACHE_PATH]
                       [--vocab-size VOCAB_SIZE] [--vocab-file VOCAB_FILE]
                       [--merge-file MERGE_FILE]
                       [--vocab-extra-ids VOCAB_EXTRA_IDS]
                       [--seq-length SEQ_LENGTH]
                       [--encoder-seq-length ENCODER_SEQ_LENGTH]
                       [--decoder-seq-length DECODER_SEQ_LENGTH]
                       [--retriever-seq-length RETRIEVER_SEQ_LENGTH]
                       [--sample-rate SAMPLE_RATE] [--mask-prob MASK_PROB]
                       [--short-seq-prob SHORT_SEQ_PROB] [--mmap-warmup]
                       [--num-workers NUM_WORKERS]
                       [--tokenizer-type {BertWordPieceLowerCase,BertWordPieceCase,GPT2BPETokenizer,SentencePieceTokenizer,GPTSentencePieceTokenizer,NullTokenizer}]
                       [--tokenizer-model TOKENIZER_MODEL]
                       [--data-impl {mmap,infer}] [--reset-position-ids]
                       [--reset-attention-mask] [--eod-mask-loss]
                       [--train-data-exact-num-epochs TRAIN_DATA_EXACT_NUM_EPOCHS]
                       [--return-data-index]
                       [--data-efficiency-curriculum-learning]
                       [--train-idx-path TRAIN_IDX_PATH]
                       [--train-desc-path TRAIN_DESC_PATH]
                       [--train-doc-idx-path TRAIN_DOC_IDX_PATH]
                       [--train-sample-idx-path TRAIN_SAMPLE_IDX_PATH]
                       [--train-shuffle-idx-path TRAIN_SHUFFLE_IDX_PATH]
                       [--adlr-autoresume]
                       [--adlr-autoresume-interval ADLR_AUTORESUME_INTERVAL]
                       [--ict-head-size ICT_HEAD_SIZE]
                       [--biencoder-projection-dim BIENCODER_PROJECTION_DIM]
                       [--biencoder-shared-query-context-model]
                       [--ict-load ICT_LOAD] [--bert-load BERT_LOAD]
                       [--titles-data-path TITLES_DATA_PATH]
                       [--query-in-block-prob QUERY_IN_BLOCK_PROB]
                       [--use-one-sent-docs]
                       [--evidence-data-path EVIDENCE_DATA_PATH]
                       [--retriever-report-topk-accuracies RETRIEVER_REPORT_TOPK_ACCURACIES [RETRIEVER_REPORT_TOPK_ACCURACIES ...]]
                       [--retriever-score-scaling]
                       [--block-data-path BLOCK_DATA_PATH]
                       [--embedding-path EMBEDDING_PATH]
                       [--indexer-batch-size INDEXER_BATCH_SIZE]
                       [--indexer-log-interval INDEXER_LOG_INTERVAL]
                       [--num-classes NUM_CLASSES] [--img-h IMG_H]
                       [--img-w IMG_W] [--num-channels NUM_CHANNELS]
                       [--patch-dim PATCH_DIM]
                       [--classes-fraction CLASSES_FRACTION]
                       [--data-per-class-fraction DATA_PER_CLASS_FRACTION]
                       [--no-data-sharding] [--head-lr-mult HEAD_LR_MULT]
                       [--vision-pretraining]
                       [--vision-pretraining-type {classify,inpaint,dino}]
                       [--vision-backbone-type {vit,mit,swin}]
                       [--swin-backbone-type {tiny,base,h3}]
                       [--mask-type {random,row}] [--mask-factor MASK_FACTOR]
                       [--iter-per-epoch ITER_PER_EPOCH]
                       [--dino-local-img-size DINO_LOCAL_IMG_SIZE]
                       [--dino-local-crops-number DINO_LOCAL_CROPS_NUMBER]
                       [--dino-head-hidden-size DINO_HEAD_HIDDEN_SIZE]
                       [--dino-bottleneck-size DINO_BOTTLENECK_SIZE]
                       [--dino-freeze-last-layer DINO_FREEZE_LAST_LAYER]
                       [--dino-norm-last-layer]
                       [--dino-warmup-teacher-temp DINO_WARMUP_TEACHER_TEMP]
                       [--dino-teacher-temp DINO_TEACHER_TEMP]
                       [--dino-warmup-teacher-temp-epochs DINO_WARMUP_TEACHER_TEMP_EPOCHS]
                       [--log-params-norm] [--log-num-zeros-in-grad]
                       [--timing-log-level {0,1,2}]
                       [--no-barrier-with-level-1-timing]
                       [--timing-log-option {max,minmax,all}]
                       [--tensorboard-log-interval TENSORBOARD_LOG_INTERVAL]
                       [--tensorboard-queue-size TENSORBOARD_QUEUE_SIZE]
                       [--log-timers-to-tensorboard]
                       [--log-batch-size-to-tensorboard]
                       [--no-log-learnig-rate-to-tensorboard]
                       [--no-log-loss-scale-to-tensorboard]
                       [--log-validation-ppl-to-tensorboard]
                       [--log-optimizer-states-to-tensorboard]
                       [--log-memory-to-tensorboard]
                       [--log-world-size-to-tensorboard]
                       [--zero-stage ZERO_STAGE] [--zero-reduce-scatter]
                       [--zero-contigious-gradients]
                       [--zero-reduce-bucket-size ZERO_REDUCE_BUCKET_SIZE]
                       [--zero-allgather-bucket-size ZERO_ALLGATHER_BUCKET_SIZE]
                       [--remote-device {none,cpu,nvme}] [--use-pin-memory]
                       [--scattered-embeddings] [--split-transformers]
                       [--memory-centric-tiled-linear]
                       [--tile-factor TILE_FACTOR]
                       [--deepspeed-activation-checkpointing]
                       [--partition-activations] [--contigious-checkpointing]
                       [--checkpoint-in-cpu] [--synchronize-each-layer]
                       [--profile-backward]
                       [--num-layers-teacher NUM_LAYERS_TEACHER]
                       [--num-experts-teacher NUM_EXPERTS_TEACHER [NUM_EXPERTS_TEACHER ...]]
                       [--hidden-size-teacher HIDDEN_SIZE_TEACHER]
                       [--num-attention-heads-teacher NUM_ATTENTION_HEADS_TEACHER]
                       [--mos] [--kd] [--kd-alpha-ce KD_ALPHA_CE]
                       [--kd-beta-ce KD_BETA_CE] [--kd-temp KD_TEMP]
                       [--reset-iteration] [--load-teacher LOAD_TEACHER]
                       [--inference-batch-times-seqlen-threshold INFERENCE_BATCH_TIMES_SEQLEN_THRESHOLD]
                       [--max-tokens-to-oom MAX_TOKENS_TO_OOM]
                       [--output-bert-embeddings]
                       [--bert-embedder-type {megatron,huggingface}]
                       [--fp8-e4m3] [--fp8-hybrid] [--no-fp8-wgrad]
                       [--fp8-margin FP8_MARGIN] [--fp8-interval FP8_INTERVAL]
                       [--transformer-impl {local,transformer_engine}]
                       [--fp8-amax-history-len FP8_AMAX_HISTORY_LEN]
                       [--fp8-amax-compute-algo {most_recent,max}]
                       [--retro-workdir RETRO_WORKDIR] [--retro-add-retriever]
                       [--retro-cyclic-train-iters RETRO_CYCLIC_TRAIN_ITERS]
                       [--retro-encoder-layers RETRO_ENCODER_LAYERS]
                       [--retro-encoder-hidden-dropout RETRO_ENCODER_HIDDEN_DROPOUT]
                       [--retro-encoder-attention-dropout RETRO_ENCODER_ATTENTION_DROPOUT]
                       [--retro-num-neighbors RETRO_NUM_NEIGHBORS]
                       [--retro-num-retrieved-chunks RETRO_NUM_RETRIEVED_CHUNKS]
                       [--retro-return-doc-ids] [--deepspeed]
                       [--deepspeed_config DEEPSPEED_CONFIG] [--deepscale]
                       [--deepscale_config DEEPSCALE_CONFIG] [--deepspeed_mpi]
pretrain_gpt.py: error: unrecognized arguments: eyJ0cmFpbl9iYXRjaF9zaXplIjogImF1dG8iLCAidHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1IjogMSwgInN0ZXBzX3Blcl9wcmludCI6IDEwMCwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDN9LCAiZnAxNiI6IHsiZW5hYmxlZCI6IHRydWUsICJpbml0aWFsX3NjYWxlX3Bvd2VyIjogMTJ9LCAiYXV0b3R1bmluZyI6IHsiZW5hYmxlZCI6IHRydWUsICJtb2RlbF9pbmZvX3BhdGgiOiAiYXV0b3R1bmluZ19yZXN1bHRzL3Byb2ZpbGVfbW9kZWxfaW5mby9tb2RlbF9pbmZvLmpzb24iLCAibW9kZWxfaW5mbyI6IHsicHJvZmlsZSI6IHRydWV9LCAibWV0cmljX3BhdGgiOiAiYXV0b3R1bmluZ19yZXN1bHRzL3Byb2ZpbGVfbW9kZWxfaW5mby9tZXRyaWNzLmpzb24ifSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZSwgInF1YW50aXplX3RyYWluaW5nIjogeyJlbmFibGVkIjogdHJ1ZSwgInF1YW50aXplX3ZlcmJvc2UiOiB0cnVlLCAicXVhbnRpemVyX2tlcm5lbCI6IHRydWUsICJxdWFudGl6ZS1hbGdvIjogeyJxX3R5cGUiOiAic3ltbWV0cmljIn0sICJxdWFudGl6ZV9iaXRzIjogeyJzdGFydF9iaXRzIjogMTYsICJ0YXJnZXRfYml0cyI6IDh9LCAicXVhbnRpemVfc2NoZWR1bGUiOiB7InF1YW50aXplX3BlcmlvZCI6IDQwMCwgInNjaGVkdWxlX29mZnNldCI6IDB9LCAicXVhbnRpemVfZ3JvdXBzIjogOH0sICJtZW1vcnlfYnJlYWtfZG93biI6IGZhbHNlfQ== --per_device_train_batch_size 1
usage: pretrain_gpt.py [-h] [--num-layers NUM_LAYERS]
                       [--encoder-num-layers ENCODER_NUM_LAYERS]
                       [--decoder-num-layers DECODER_NUM_LAYERS]
                       [--num-experts NUM_EXPERTS [NUM_EXPERTS ...]]
                       [--mlp-type MLP_TYPE] [--topk TOPK]
                       [--expert-interval EXPERT_INTERVAL]
                       [--hidden-size HIDDEN_SIZE]
                       [--ffn-hidden-size FFN_HIDDEN_SIZE]
                       [--num-attention-heads NUM_ATTENTION_HEADS]
                       [--num-key-value-heads NUM_KEY_VALUE_HEADS]
                       [--kv-channels KV_CHANNELS]
                       [--max-position-embeddings MAX_POSITION_EMBEDDINGS]
                       [--use-rotary-position-embeddings]
                       [--rotary-percent ROTARY_PERCENT]
                       [--no-position-embedding]
                       [--make-vocab-size-divisible-by MAKE_VOCAB_SIZE_DIVISIBLE_BY]
                       [--normalization {layernorm,rmsnorm}]
                       [--layernorm-epsilon LAYERNORM_EPSILON]
                       [--apply-layernorm-1p] [--disable-mem-efficient-ln]
                       [--apply-residual-connection-post-layernorm]
                       [--openai-gelu] [--squared-relu] [--swiglu]
                       [--onnx-safe ONNX_SAFE] [--bert-no-binary-head]
                       [--num-experts-switch NUM_EXPERTS_SWITCH]
                       [--untie-embeddings-and-output-weights]
                       [--embedding-weights-in-fp32]
                       [--attention-dropout ATTENTION_DROPOUT]
                       [--hidden-dropout HIDDEN_DROPOUT]
                       [--weight-decay WEIGHT_DECAY]
                       [--start-weight-decay START_WEIGHT_DECAY]
                       [--end-weight-decay END_WEIGHT_DECAY]
                       [--weight-decay-incr-style {constant,linear,cosine}]
                       [--clip-grad CLIP_GRAD] [--adam-beta1 ADAM_BETA1]
                       [--adam-beta2 ADAM_BETA2] [--adam-eps ADAM_EPS]
                       [--sgd-momentum SGD_MOMENTUM]
                       [--micro-batch-size MICRO_BATCH_SIZE]
                       [--batch-size BATCH_SIZE]
                       [--global-batch-size GLOBAL_BATCH_SIZE]
                       [--rampup-batch-size [RAMPUP_BATCH_SIZE ...]]
                       [--recompute-activations]
                       [--recompute-granularity {full,selective}]
                       [--distribute-saved-activations]
                       [--recompute-method {uniform,block}]
                       [--recompute-num-layers RECOMPUTE_NUM_LAYERS]
                       [--checkpoint-activations]
                       [--distribute-checkpointed-activations]
                       [--checkpoint-num-layers CHECKPOINT_NUM_LAYERS]
                       [--train-iters TRAIN_ITERS]
                       [--train-samples TRAIN_SAMPLES]
                       [--train-tokens TRAIN_TOKENS] [--random-ltd]
                       [--log-interval LOG_INTERVAL]
                       [--exit-interval EXIT_INTERVAL]
                       [--exit-duration-in-mins EXIT_DURATION_IN_MINS]
                       [--exit-signal-handler]
                       [--tensorboard-dir TENSORBOARD_DIR]
                       [--no-masked-softmax-fusion] [--no-bias-gelu-fusion]
                       [--no-bias-dropout-fusion]
                       [--disable-moe-token-dropping]
                       [--moe-train-capacity-factor MOE_TRAIN_CAPACITY_FACTOR]
                       [--moe-eval-capacity-factor MOE_EVAL_CAPACITY_FACTOR]
                       [--moe-min-capacity MOE_MIN_CAPACITY]
                       [--moe-loss-coeff MOE_LOSS_COEFF]
                       [--create-moe-param-group] [--use-flash-attn]
                       [--use-flash-attn-v2] [--use-flash-attn-triton]
                       [--disable-bias-linear] [--optimizer {adam,sgd}]
                       [--dataloader-type {single,cyclic}] [--ds-inference]
                       [--cpu-optimizer] [--cpu_torch_adam]
                       [--no-pipeline-parallel] [--use-tutel] [--inference]
                       [--no-async-tensor-model-parallel-allreduce]
                       [--no-persist-layer-norm] [--sequence-parallel]
                       [--ds-sequence-parallel-size DS_SEQUENCE_PARALLEL_SIZE]
                       [--force-ds-sequence-parallel]
                       [--no-gradient-accumulation-fusion]
                       [--use-dataset-only USE_DATASET_ONLY] [--seed SEED]
                       [--data-parallel-random-init]
                       [--init-method-std INIT_METHOD_STD]
                       [--init-method-xavier-uniform] [--lr LR]
                       [--lr-decay-style {constant,linear,cosine,inverse-square-root}]
                       [--lr-decay-iters LR_DECAY_ITERS]
                       [--lr-decay-samples LR_DECAY_SAMPLES]
                       [--lr-decay-tokens LR_DECAY_TOKENS]
                       [--lr-warmup-fraction LR_WARMUP_FRACTION]
                       [--lr-warmup-iters LR_WARMUP_ITERS]
                       [--lr-warmup-samples LR_WARMUP_SAMPLES]
                       [--lr-warmup-tokens LR_WARMUP_TOKENS] [--warmup WARMUP]
                       [--min-lr MIN_LR] [--override-opt_param-scheduler]
                       [--use-checkpoint-opt_param-scheduler] [--save SAVE]
                       [--save-interval SAVE_INTERVAL] [--no-save-optim]
                       [--no-save-rng] [--load LOAD] [--no-load-optim]
                       [--no-load-rng] [--no-load-lr-state] [--finetune]
                       [--no-initialization] [--use-checkpoint-args]
                       [--exit-on-missing-checkpoint] [--universal-checkpoint]
                       [--fp16] [--bf16] [--loss-scale LOSS_SCALE]
                       [--initial-loss-scale INITIAL_LOSS_SCALE]
                       [--min-loss-scale MIN_LOSS_SCALE]
                       [--loss-scale-window LOSS_SCALE_WINDOW]
                       [--hysteresis HYSTERESIS] [--fp32-residual-connection]
                       [--no-query-key-layer-scaling]
                       [--attention-softmax-in-fp32]
                       [--accumulate-allreduce-grads-in-fp32]
                       [--fp16-lm-cross-entropy]
                       [--tensor-model-parallel-size TENSOR_MODEL_PARALLEL_SIZE]
                       [--enable-expert-tensor-parallelism]
                       [--pipeline-model-parallel-size PIPELINE_MODEL_PARALLEL_SIZE]
                       [--pipeline-model-parallel-split-rank PIPELINE_MODEL_PARALLEL_SPLIT_RANK]
                       [--moe-expert-parallel-size MOE_EXPERT_PARALLEL_SIZE]
                       [--model-parallel-size MODEL_PARALLEL_SIZE]
                       [--num-layers-per-virtual-pipeline-stage NUM_LAYERS_PER_VIRTUAL_PIPELINE_STAGE]
                       [--overlap-p2p-communication]
                       [--distributed-backend {nccl,gloo,ccl}]
                       [--distributed-timeout-minutes DISTRIBUTED_TIMEOUT_MINUTES]
                       [--DDP-impl {local,torch,FSDP}]
                       [--no-contiguous-buffers-in-local-ddp]
                       [--no-scatter-gather-tensors-in-pipeline]
                       [--use-ring-exchange-p2p] [--local-rank LOCAL_RANK]
                       [--lazy-mpu-init LAZY_MPU_INIT]
                       [--use-cpu-initialization]
                       [--empty-unused-memory-level {0,1,2}]
                       [--standalone-embedding-stage]
                       [--use-distributed-optimizer] [--eval-iters EVAL_ITERS]
                       [--eval-interval EVAL_INTERVAL] [--skip-train]
                       [--aml-data-download-path AML_DATA_DOWNLOAD_PATH]
                       [--data-path [DATA_PATH ...]] [--split SPLIT]
                       [--train-data-path [TRAIN_DATA_PATH ...]]
                       [--valid-data-path [VALID_DATA_PATH ...]]
                       [--test-data-path [TEST_DATA_PATH ...]]
                       [--data-cache-path DATA_CACHE_PATH]
                       [--vocab-size VOCAB_SIZE] [--vocab-file VOCAB_FILE]
                       [--merge-file MERGE_FILE]
                       [--vocab-extra-ids VOCAB_EXTRA_IDS]
                       [--seq-length SEQ_LENGTH]
                       [--encoder-seq-length ENCODER_SEQ_LENGTH]
                       [--decoder-seq-length DECODER_SEQ_LENGTH]
                       [--retriever-seq-length RETRIEVER_SEQ_LENGTH]
                       [--sample-rate SAMPLE_RATE] [--mask-prob MASK_PROB]
                       [--short-seq-prob SHORT_SEQ_PROB] [--mmap-warmup]
                       [--num-workers NUM_WORKERS]
                       [--tokenizer-type {BertWordPieceLowerCase,BertWordPieceCase,GPT2BPETokenizer,SentencePieceTokenizer,GPTSentencePieceTokenizer,NullTokenizer}]
                       [--tokenizer-model TOKENIZER_MODEL]
                       [--data-impl {mmap,infer}] [--reset-position-ids]
                       [--reset-attention-mask] [--eod-mask-loss]
                       [--train-data-exact-num-epochs TRAIN_DATA_EXACT_NUM_EPOCHS]
                       [--return-data-index]
                       [--data-efficiency-curriculum-learning]
                       [--train-idx-path TRAIN_IDX_PATH]
                       [--train-desc-path TRAIN_DESC_PATH]
                       [--train-doc-idx-path TRAIN_DOC_IDX_PATH]
                       [--train-sample-idx-path TRAIN_SAMPLE_IDX_PATH]
                       [--train-shuffle-idx-path TRAIN_SHUFFLE_IDX_PATH]
                       [--adlr-autoresume]
                       [--adlr-autoresume-interval ADLR_AUTORESUME_INTERVAL]
                       [--ict-head-size ICT_HEAD_SIZE]
                       [--biencoder-projection-dim BIENCODER_PROJECTION_DIM]
                       [--biencoder-shared-query-context-model]
                       [--ict-load ICT_LOAD] [--bert-load BERT_LOAD]
                       [--titles-data-path TITLES_DATA_PATH]
                       [--query-in-block-prob QUERY_IN_BLOCK_PROB]
                       [--use-one-sent-docs]
                       [--evidence-data-path EVIDENCE_DATA_PATH]
                       [--retriever-report-topk-accuracies RETRIEVER_REPORT_TOPK_ACCURACIES [RETRIEVER_REPORT_TOPK_ACCURACIES ...]]
                       [--retriever-score-scaling]
                       [--block-data-path BLOCK_DATA_PATH]
                       [--embedding-path EMBEDDING_PATH]
                       [--indexer-batch-size INDEXER_BATCH_SIZE]
                       [--indexer-log-interval INDEXER_LOG_INTERVAL]
                       [--num-classes NUM_CLASSES] [--img-h IMG_H]
                       [--img-w IMG_W] [--num-channels NUM_CHANNELS]
                       [--patch-dim PATCH_DIM]
                       [--classes-fraction CLASSES_FRACTION]
                       [--data-per-class-fraction DATA_PER_CLASS_FRACTION]
                       [--no-data-sharding] [--head-lr-mult HEAD_LR_MULT]
                       [--vision-pretraining]
                       [--vision-pretraining-type {classify,inpaint,dino}]
                       [--vision-backbone-type {vit,mit,swin}]
                       [--swin-backbone-type {tiny,base,h3}]
                       [--mask-type {random,row}] [--mask-factor MASK_FACTOR]
                       [--iter-per-epoch ITER_PER_EPOCH]
                       [--dino-local-img-size DINO_LOCAL_IMG_SIZE]
                       [--dino-local-crops-number DINO_LOCAL_CROPS_NUMBER]
                       [--dino-head-hidden-size DINO_HEAD_HIDDEN_SIZE]
                       [--dino-bottleneck-size DINO_BOTTLENECK_SIZE]
                       [--dino-freeze-last-layer DINO_FREEZE_LAST_LAYER]
                       [--dino-norm-last-layer]
                       [--dino-warmup-teacher-temp DINO_WARMUP_TEACHER_TEMP]
                       [--dino-teacher-temp DINO_TEACHER_TEMP]
                       [--dino-warmup-teacher-temp-epochs DINO_WARMUP_TEACHER_TEMP_EPOCHS]
                       [--log-params-norm] [--log-num-zeros-in-grad]
                       [--timing-log-level {0,1,2}]
                       [--no-barrier-with-level-1-timing]
                       [--timing-log-option {max,minmax,all}]
                       [--tensorboard-log-interval TENSORBOARD_LOG_INTERVAL]
                       [--tensorboard-queue-size TENSORBOARD_QUEUE_SIZE]
                       [--log-timers-to-tensorboard]
                       [--log-batch-size-to-tensorboard]
                       [--no-log-learnig-rate-to-tensorboard]
                       [--no-log-loss-scale-to-tensorboard]
                       [--log-validation-ppl-to-tensorboard]
                       [--log-optimizer-states-to-tensorboard]
                       [--log-memory-to-tensorboard]
                       [--log-world-size-to-tensorboard]
                       [--zero-stage ZERO_STAGE] [--zero-reduce-scatter]
                       [--zero-contigious-gradients]
                       [--zero-reduce-bucket-size ZERO_REDUCE_BUCKET_SIZE]
                       [--zero-allgather-bucket-size ZERO_ALLGATHER_BUCKET_SIZE]
                       [--remote-device {none,cpu,nvme}] [--use-pin-memory]
                       [--scattered-embeddings] [--split-transformers]
                       [--memory-centric-tiled-linear]
                       [--tile-factor TILE_FACTOR]
                       [--deepspeed-activation-checkpointing]
                       [--partition-activations] [--contigious-checkpointing]
                       [--checkpoint-in-cpu] [--synchronize-each-layer]
                       [--profile-backward]
                       [--num-layers-teacher NUM_LAYERS_TEACHER]
                       [--num-experts-teacher NUM_EXPERTS_TEACHER [NUM_EXPERTS_TEACHER ...]]
                       [--hidden-size-teacher HIDDEN_SIZE_TEACHER]
                       [--num-attention-heads-teacher NUM_ATTENTION_HEADS_TEACHER]
                       [--mos] [--kd] [--kd-alpha-ce KD_ALPHA_CE]
                       [--kd-beta-ce KD_BETA_CE] [--kd-temp KD_TEMP]
                       [--reset-iteration] [--load-teacher LOAD_TEACHER]
                       [--inference-batch-times-seqlen-threshold INFERENCE_BATCH_TIMES_SEQLEN_THRESHOLD]
                       [--max-tokens-to-oom MAX_TOKENS_TO_OOM]
                       [--output-bert-embeddings]
                       [--bert-embedder-type {megatron,huggingface}]
                       [--fp8-e4m3] [--fp8-hybrid] [--no-fp8-wgrad]
                       [--fp8-margin FP8_MARGIN] [--fp8-interval FP8_INTERVAL]
                       [--transformer-impl {local,transformer_engine}]
                       [--fp8-amax-history-len FP8_AMAX_HISTORY_LEN]
                       [--fp8-amax-compute-algo {most_recent,max}]
                       [--retro-workdir RETRO_WORKDIR] [--retro-add-retriever]
                       [--retro-cyclic-train-iters RETRO_CYCLIC_TRAIN_ITERS]
                       [--retro-encoder-layers RETRO_ENCODER_LAYERS]
                       [--retro-encoder-hidden-dropout RETRO_ENCODER_HIDDEN_DROPOUT]
                       [--retro-encoder-attention-dropout RETRO_ENCODER_ATTENTION_DROPOUT]
                       [--retro-num-neighbors RETRO_NUM_NEIGHBORS]
                       [--retro-num-retrieved-chunks RETRO_NUM_RETRIEVED_CHUNKS]
                       [--retro-return-doc-ids] [--deepspeed]
                       [--deepspeed_config DEEPSPEED_CONFIG] [--deepscale]
                       [--deepscale_config DEEPSCALE_CONFIG] [--deepspeed_mpi]
pretrain_gpt.py: error: unrecognized arguments: eyJ0cmFpbl9iYXRjaF9zaXplIjogImF1dG8iLCAidHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1IjogMSwgInN0ZXBzX3Blcl9wcmludCI6IDEwMCwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDN9LCAiZnAxNiI6IHsiZW5hYmxlZCI6IHRydWUsICJpbml0aWFsX3NjYWxlX3Bvd2VyIjogMTJ9LCAiYXV0b3R1bmluZyI6IHsiZW5hYmxlZCI6IHRydWUsICJtb2RlbF9pbmZvX3BhdGgiOiAiYXV0b3R1bmluZ19yZXN1bHRzL3Byb2ZpbGVfbW9kZWxfaW5mby9tb2RlbF9pbmZvLmpzb24iLCAibW9kZWxfaW5mbyI6IHsicHJvZmlsZSI6IHRydWV9LCAibWV0cmljX3BhdGgiOiAiYXV0b3R1bmluZ19yZXN1bHRzL3Byb2ZpbGVfbW9kZWxfaW5mby9tZXRyaWNzLmpzb24ifSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZSwgInF1YW50aXplX3RyYWluaW5nIjogeyJlbmFibGVkIjogdHJ1ZSwgInF1YW50aXplX3ZlcmJvc2UiOiB0cnVlLCAicXVhbnRpemVyX2tlcm5lbCI6IHRydWUsICJxdWFudGl6ZS1hbGdvIjogeyJxX3R5cGUiOiAic3ltbWV0cmljIn0sICJxdWFudGl6ZV9iaXRzIjogeyJzdGFydF9iaXRzIjogMTYsICJ0YXJnZXRfYml0cyI6IDh9LCAicXVhbnRpemVfc2NoZWR1bGUiOiB7InF1YW50aXplX3BlcmlvZCI6IDQwMCwgInNjaGVkdWxlX29mZnNldCI6IDB9LCAicXVhbnRpemVfZ3JvdXBzIjogOH0sICJtZW1vcnlfYnJlYWtfZG93biI6IGZhbHNlfQ== --per_device_train_batch_size 1
